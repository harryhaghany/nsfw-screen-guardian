# nsfw-screen-guardian
> An AI-powered real-time NSFW content detection system that monitors the userâ€™s screen using a mss and prevents exposure to inappropriate content by locking the device.
> https://youtu.be/qCTQZGpU8Mo

## ğŸš€ Features

- ğŸ” Screen monitoring via mms library
- ğŸ§  Trained CNN model (ResNet) to classify NSFW content
- â›” Automatic response upon detection 
- ğŸ“Š Model accuracy reporting and easy retraining with your dataset
- ğŸ” Supports adding parental controls or productivity blockers

## ğŸ“¦ Tech Stack

- Python ğŸ
- PyTorch / FastAI ğŸ§ 
- OpenCV ğŸ“·
- PIL ğŸ–¼ï¸
- Torchvision ğŸ“¦

## ğŸ“ Dataset

This project uses a labeled dataset of images for training NSFW vs Safe classifiers.
You can replace it with your own by placing it in `nsfw_dataset_v1/` and using appropriate class folders like:
nsfw_dataset_v1/
â”œâ”€â”€ porn/
â”œâ”€â”€ neutral/

## ğŸ Getting Started

```bash
git clone https://github.com/yourusername/screen-sentinel.git
cd screen-sentinel
pip install -r requirements.txt
python train.py
python run_detector.py
